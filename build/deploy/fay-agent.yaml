---
# Source: kubefay/templates/agent/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: kubefay-agent
  namespace: kube-system
  labels:
    app: kubefay
---
# Source: kubefay/templates/controller/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: kubefay-controller
  namespace: kube-system
  labels:
    app: kubefay
---
# Source: kubefay/templates/agent/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: kubefay-agent
  namespace: kube-system
  annotations:
    kubernetes.io/service-account.name: kubefay-agent
type: kubernetes.io/service-account-token
---
# Source: kubefay/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: kubefay-config
  namespace: kube-system
  labels:
    app: kubefay
data:
  kubefay-agent.conf: |
    # FeatureGates is a map of feature names to bools that enable or disable experimental features.
    featureGates:
    # Enable kubefayProxy which provides ServiceLB for in-cluster Services in kubefay-agent.
    # It should be enabled on Windows, otherwise NetworkPolicy will not take effect on
    # Service traffic.
    #  kubefayProxy: true

    # Enable EndpointSlice support in kubefayProxy. Don't enable this feature unless that EndpointSlice
    # API version v1beta1 is supported and set as enabled in Kubernetes. If kubefayProxy is not enabled,
    # this flag will not take effect.
    #  EndpointSlice: false

    # Enable traceflow which provides packet tracing feature to diagnose network issue.
    #  Traceflow: true

    # Enable NodePortLocal feature to make the Pods reachable externally through NodePort
    #  NodePortLocal: true

    # Enable kubefay ClusterNetworkPolicy feature to complement K8s NetworkPolicy for cluster admins
    # to define security policies which apply to the entire cluster, and kubefay NetworkPolicy
    # feature that supports priorities, rule actions and externalEntities in the future.
    #  kubefayPolicy: true

    # Enable flowexporter which exports polled conntrack connections as IPFIX flow records from each
    # agent to a configured collector.
    #  FlowExporter: false

    # Enable collecting and exposing NetworkPolicy statistics.
    #  NetworkPolicyStats: true

    # Enable controlling SNAT IPs of Pod egress traffic.
    #  Egress: true

    # Enable kubefayIPAM, which can allocate IP addresses from IPPools. kubefayIPAM is required by the
    # bridging mode and allocates IPs to Pods in bridging mode. It is also required to use kubefay for
    # IPAM when configuring secondary network interfaces with Multus.
    #  kubefayIPAM: false

    # Enable multicast traffic. This feature is supported only with noEncap mode.
    #  Multicast: false

    # Enable support for provisioning secondary network interfaces for Pods (using
    # Pod annotations). At the moment, kubefay can only create secondary network
    # interfaces using SR-IOV VFs on baremetal Nodes.
    #  SecondaryNetwork: false

    # Enable managing external IPs of Services of LoadBalancer type.
    #  ServiceExternalIP: false

    # Enable mirroring or redirecting the traffic Pods send or receive.
    #  TrafficControl: false

    # Name of the OpenVSwitch bridge kubefay-agent will create and use.
    # Make sure it doesn't conflict with your existing OpenVSwitch bridges.
    ovsBridge: "br-int"

    # Datapath type to use for the OpenVSwitch bridge created by kubefay. Supported values are:
    # - system
    # - netdev
    # 'system' is the default value and corresponds to the kernel datapath. Use 'netdev' to run
    # OVS in userspace mode. Userspace mode requires the tun device driver to be available.
    #ovsDatapathType: system

    # Name of the interface kubefay-agent will create and use for host <--> pod communication.
    # Make sure it doesn't conflict with your existing interfaces.
    hostGateway: "kubefay-gw0"

    # Determines how traffic is encapsulated. It has the following options:
    # encap(default):    Inter-node Pod traffic is always encapsulated and Pod to external network
    #                    traffic is SNAT'd.
    # noEncap:           Inter-node Pod traffic is not encapsulated; Pod to external network traffic is
    #                    SNAT'd if noSNAT is not set to true. Underlying network must be capable of
    #                    supporting Pod traffic across IP subnets.
    # hybrid:            noEncap if source and destination Nodes are on the same subnet, otherwise encap.
    # networkPolicyOnly: kubefay enforces NetworkPolicy only, and utilizes CNI chaining and delegates Pod
    #                    IPAM and connectivity to the primary CNI.
    #
    trafficEncapMode: "encap"

    # Whether or not to SNAT (using the Node IP) the egress traffic from a Pod to the external network.
    # This option is for the noEncap traffic mode only, and the default value is false. In the noEncap
    # mode, if the cluster's Pod CIDR is reachable from the external network, then the Pod traffic to
    # the external network needs not be SNAT'd. In the networkPolicyOnly mode, kubefay-agent never
    # performs SNAT and this option will be ignored; for other modes it must be set to false.
    noSNAT: false

    # Tunnel protocols used for encapsulating traffic across Nodes. If WireGuard is enabled in trafficEncryptionMode,
    # this option will not take effect. Supported values:
    # - geneve (default)
    # - vxlan
    # - gre
    # - stt
    # Note that "gre" is not supported for IPv6 clusters (IPv6-only or dual-stack clusters).
    tunnelType: "geneve"

    # Determines how tunnel traffic is encrypted. Currently encryption only works with encap mode.
    # It has the following options:
    # - none (default):  Inter-node Pod traffic will not be encrypted.
    # - ipsec:           Enable IPsec (ESP) encryption for Pod traffic across Nodes. kubefay uses
    #                    Preshared Key (PSK) for IKE authentication. When IPsec tunnel is enabled,
    #                    the PSK value must be passed to kubefay Agent through an environment
    #                    variable: kubefay_IPSEC_PSK.
    # - wireGuard:       Enable WireGuard for tunnel traffic encryption.
    trafficEncryptionMode: "none"

    # Enable bridging mode of Pod network on Nodes, in which the Node's transport interface is connected
    # to the OVS bridge, and cross-Node/VLAN traffic of kubefayIPAM Pods (Pods whose IP addresses are
    # allocated by kubefayIPAM from IPPools) is sent to the underlay network, and forwarded/routed by the
    # underlay network.
    # This option requires the `kubefayIPAM` feature gate to be enabled. At this moment, it supports only
    # IPv4 and Linux Nodes, and can be enabled only when `ovsDatapathType` is `system`,
    # `trafficEncapMode` is `noEncap`, and `noSNAT` is true.
    enableBridgingMode: false

    # Disable TX checksum offloading for container network interfaces. It's supposed to be set to true when the
    # datapath doesn't support TX checksum offloading, which causes packets to be dropped due to bad checksum.
    # It affects Pods running on Linux Nodes only.
    disableTXChecksumOffload: false

    # Default MTU to use for the host gateway interface and the network interface of each Pod.
    # If omitted, kubefay-agent will discover the MTU of the Node's primary interface and
    # also adjust MTU to accommodate for tunnel encapsulation overhead (if applicable).
    defaultMTU: 0

    # wireGuard specifies WireGuard related configurations.
    wireGuard:
      # The port for WireGuard to receive traffic.
      port: 51820

    egress:
      # exceptCIDRs is the CIDR ranges to which outbound Pod traffic will not be SNAT'd by Egresses.
      exceptCIDRs:

    # ClusterIP CIDR range for Services. It's required when kubefayProxy is not enabled, and should be
    # set to the same value as the one specified by --service-cluster-ip-range for kube-apiserver. When
    # kubefayProxy is enabled, this parameter is not needed and will be ignored if provided.
    serviceCIDR: ""

    # ClusterIP CIDR range for IPv6 Services. It's required when using kube-proxy to provide IPv6 Service in a Dual-Stack
    # cluster or an IPv6 only cluster. The value should be the same as the configuration for kube-apiserver specified by
    # --service-cluster-ip-range. When kubefayProxy is enabled, this parameter is not needed.
    # No default value for this field.
    serviceCIDRv6: ""

    # The port for the kubefay-agent APIServer to serve on.
    # Note that if it's set to another value, the `containerPort` of the `api` port of the
    # `kubefay-agent` container must be set to the same value.
    apiPort: 10350

    # Enable metrics exposure via Prometheus. Initializes Prometheus metrics listener.
    enablePrometheusMetrics: true

    # Provide the IPFIX collector address as a string with format <HOST>:[<PORT>][:<PROTO>].
    # HOST can either be the DNS name or the IP of the Flow Collector. For example,
    # "flow-aggregator.flow-aggregator.svc" can be provided as DNS name to connect
    # to the kubefay Flow Aggregator service. If IP, it can be either IPv4 or IPv6.
    # However, IPv6 address should be wrapped with [].
    # If PORT is empty, we default to 4739, the standard IPFIX port.
    # If no PROTO is given, we consider "tls" as default. We support "tls", "tcp" and
    # "udp" protocols. "tls" is used for securing communication between flow exporter and
    # flow aggregator.
    flowCollectorAddr: "flow-aggregator.flow-aggregator.svc:4739:tls"

    # Provide flow poll interval as a duration string. This determines how often the
    # flow exporter dumps connections from the conntrack module. Flow poll interval
    # should be greater than or equal to 1s (one second).
    # Valid time units are "ns", "us" (or "µs"), "ms", "s", "m", "h".
    flowPollInterval: "5s"

    # Provide the active flow export timeout, which is the timeout after which a flow
    # record is sent to the collector for active flows. Thus, for flows with a continuous
    # stream of packets, a flow record will be exported to the collector once the elapsed
    # time since the last export event is equal to the value of this timeout.
    # Valid time units are "ns", "us" (or "µs"), "ms", "s", "m", "h".
    activeFlowExportTimeout: "5s"

    # Provide the idle flow export timeout, which is the timeout after which a flow
    # record is sent to the collector for idle flows. A flow is considered idle if no
    # packet matching this flow has been observed since the last export event.
    # Valid time units are "ns", "us" (or "µs"), "ms", "s", "m", "h".
    idleFlowExportTimeout: "15s"

    nodePortLocal:
    # Enable NodePortLocal, a feature used to make Pods reachable using port forwarding on the host. To
    # enable this feature, you need to set "enable" to true, and ensure that the NodePortLocal feature
    # gate is also enabled (which is the default).
      enable: false
    # Provide the port range used by NodePortLocal. When the NodePortLocal feature is enabled, a port
    # from that range will be assigned whenever a Pod's container defines a specific port to be exposed
    # (each container can define a list of ports as pod.spec.containers[].ports), and all Node traffic
    # directed to that port will be forwarded to the Pod.
      portRange: "61000-62000"

    # Provide the address of Kubernetes apiserver, to override any value provided in kubeconfig or InClusterConfig.
    # Defaults to "". It must be a host string, a host:port pair, or a URL to the base of the apiserver.
    kubeAPIServerOverride: ""

    # Comma-separated list of Cipher Suites. If omitted, the default Go Cipher Suites will be used.
    # https://golang.org/pkg/crypto/tls/#pkg-constants
    # Note that TLS1.3 Cipher Suites cannot be added to the list. But the apiserver will always
    # prefer TLS1.3 Cipher Suites whenever possible.
    tlsCipherSuites: ""

    # TLS min version from: VersionTLS10, VersionTLS11, VersionTLS12, VersionTLS13.
    tlsMinVersion: ""

    # The name of the interface on Node which is used for tunneling or routing the traffic across Nodes.
    # If there are multiple IP addresses configured on the interface, the first one is used. The IP
    # address used for tunneling or routing traffic to remote Nodes is decided in the following order of
    # preference (from highest to lowest):
    # 1. transportInterface
    # 2. transportInterfaceCIDRs
    # 3. The Node IP
    transportInterface: ""

    multicast:
    # The names of the interfaces on Nodes that are used to forward multicast traffic.
    # Defaults to transport interface if not set.
      multicastInterfaces:

    # The interval at which the kubefay-agent sends IGMP queries to Pods.
    # Valid time units are "ns", "us" (or "µs"), "ms", "s", "m", "h".
      igmpQueryInterval: "125s"

    # The network CIDRs of the interface on Node which is used for tunneling or routing the traffic across
    # Nodes. If there are multiple interfaces configured the same network CIDR, the first one is used. The
    # IP address used for tunneling or routing traffic to remote Nodes is decided in the following order of
    # preference (from highest to lowest):
    # 1. transportInterface
    # 2. transportInterfaceCIDRs
    # 3. The Node IP
    transportInterfaceCIDRs:

    # Option kubefayProxy contains kubefayProxy related configuration options.
    kubefayProxy:
      # ProxyAll tells kubefay-agent to proxy all Service traffic, including NodePort, LoadBalancer, and ClusterIP traffic,
      # regardless of where they come from. Therefore, running kube-proxy is no longer required. This requires the kubefayProxy
      # feature to be enabled.
      # Note that this option is experimental. If kube-proxy is removed, option kubeAPIServerOverride must be used to access
      # apiserver directly.
      proxyAll: false
      # A string array of values which specifies the host IPv4/IPv6 addresses for NodePort. Values can be valid IP blocks.
      # (e.g. 1.2.3.0/24, 1.2.3.4/32). An empty string slice is meant to select all host IPv4/IPv6 addresses.
      # Note that the option is only valid when proxyAll is true.
      nodePortAddresses:
      # An array of string values to specify a list of Services which should be ignored by kubefayProxy (traffic to these
      # Services will not be load-balanced). Values can be a valid ClusterIP (e.g. 10.11.1.2) or a Service name
      # with Namespace (e.g. kube-system/kube-dns)
      skipServices:
      # When ProxyLoadBalancerIPs is set to false, kubefayProxy no longer load-balances traffic destined to the
      # External IPs of LoadBalancer Services. This is useful when the external LoadBalancer provides additional
      # capabilities (e.g. TLS termination) and it is desirable for Pod-to-ExternalIP traffic to be sent to the
      # external LoadBalancer instead of being load-balanced to an Endpoint directly by kubefayProxy.
      # Note that setting ProxyLoadBalancerIPs to false usually only makes sense when ProxyAll is set to true and
      # kube-proxy is removed from the cluser, otherwise kube-proxy will still load-balance this traffic.
      proxyLoadBalancerIPs: true
  kubefay-cni.conflist: |
    {
        "cniVersion":"0.3.0",
        "name": "kubefay",
        "plugins": [
            {
                "type": "kubefay",
                "ipam": {
                    "type": "host-local"
                }
            }
            ,
            {
                "type": "portmap",
                "capabilities": {"portMappings": true}
            }
            ,
            {
                "type": "bandwidth",
                "capabilities": {"bandwidth": true}
            }
        ]
    }
  kubefay-controller.conf: |
    # FeatureGates is a map of feature names to bools that enable or disable experimental features.
    featureGates:
    # Enable traceflow which provides packet tracing feature to diagnose network issue.
    #  Traceflow: true

    # Enable kubefay ClusterNetworkPolicy feature to complement K8s NetworkPolicy for cluster admins
    # to define security policies which apply to the entire cluster, and kubefay NetworkPolicy
    # feature that supports priorities, rule actions and externalEntities in the future.
    #  kubefayPolicy: true

    # Enable collecting and exposing NetworkPolicy statistics.
    #  NetworkPolicyStats: true

    # Enable controlling SNAT IPs of Pod egress traffic.
    #  Egress: true

    # Run Kubernetes NodeIPAMController with kubefay.
    #  NodeIPAM: false

    # Enable kubefayIPAM, which can allocate IP addresses from IPPools. kubefayIPAM is required by the
    # bridging mode and allocates IPs to Pods in bridging mode. It is also required to use kubefay for
    # IPAM when configuring secondary network interfaces with Multus.
    #  kubefayIPAM: false

    # Enable managing external IPs of Services of LoadBalancer type.
    #  ServiceExternalIP: false

    # The port for the kubefay-controller APIServer to serve on.
    # Note that if it's set to another value, the `containerPort` of the `api` port of the
    # `kubefay-controller` container must be set to the same value.
    apiPort: 10349

    # Enable metrics exposure via Prometheus. Initializes Prometheus metrics listener.
    enablePrometheusMetrics: true

    # Indicates whether to use auto-generated self-signed TLS certificate.
    # If false, a Secret named "kubefay-controller-tls" must be provided with the following keys:
    #   ca.crt: <CA certificate>
    #   tls.crt: <TLS certificate>
    #   tls.key: <TLS private key>
    selfSignedCert: true

    # Comma-separated list of Cipher Suites. If omitted, the default Go Cipher Suites will be used.
    # https://golang.org/pkg/crypto/tls/#pkg-constants
    # Note that TLS1.3 Cipher Suites cannot be added to the list. But the apiserver will always
    # prefer TLS1.3 Cipher Suites whenever possible.
    tlsCipherSuites: ""

    # TLS min version from: VersionTLS10, VersionTLS11, VersionTLS12, VersionTLS13.
    tlsMinVersion: ""

    nodeIPAM:
      # Enable the integrated Node IPAM controller within the kubefay controller.
      enableNodeIPAM: false
      # CIDR ranges for Pods in cluster. String array containing single CIDR range, or multiple ranges.
      # The CIDRs could be either IPv4 or IPv6. At most one CIDR may be specified for each IP family.
      # Value ignored when enableNodeIPAM is false.
      clusterCIDRs:
      # CIDR ranges for Services in cluster. It is not necessary to specify it when there is no overlap with clusterCIDRs.
      # Value ignored when enableNodeIPAM is false.
      serviceCIDR: ""
      serviceCIDRv6: ""
      # Mask size for IPv4 Node CIDR in IPv4 or dual-stack cluster. Value ignored when enableNodeIPAM is false
      # or when IPv4 Pod CIDR is not configured. Valid range is 16 to 30.
      nodeCIDRMaskSizeIPv4: 24
      # Mask size for IPv6 Node CIDR in IPv6 or dual-stack cluster. Value ignored when enableNodeIPAM is false
      # or when IPv6 Pod CIDR is not configured. Valid range is 64 to 126.
      nodeCIDRMaskSizeIPv6: 64
---
# Source: kubefay/templates/agent/clusterrole.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: kubefay-agent
  labels:
    app: kubefay
rules:
  - apiGroups:
      - ""
    resources:
      - nodes
    verbs:
      - get
      - watch
      - list
  - apiGroups:
      - ""
    resources:
      - nodes/status
    verbs:
      - patch
  - apiGroups:
      - ""
    resources:
      - pods
    verbs:
      - get
      - watch
      - list
  - apiGroups:
      - ""
    resources:
      - pods/status
    verbs:
      - patch
  - apiGroups:
      - ""
    resources:
      - endpoints
      - services
      - namespaces
    verbs:
      - get
      - watch
      - list
  - apiGroups:
      - discovery.k8s.io
    resources:
      - endpointslices
    verbs:
      - get
      - watch
      - list
  - apiGroups:
      - crd.kubefay.io
    resources:
      - kubefayagentinfos
    verbs:
      - get
      - create
      - update
      - delete
  - apiGroups:
      - controlplane.kubefay.io
    resources:
      - networkpolicies
      - appliedtogroups
      - addressgroups
    verbs:
      - get
      - watch
      - list
  - apiGroups:
      - controlplane.kubefay.io
    resources:
      - egressgroups
    verbs:
      - get
      - watch
      - list
  - apiGroups:
      - controlplane.kubefay.io
    resources:
      - nodestatssummaries
    verbs:
      - create
  - apiGroups:
      - controlplane.kubefay.io
    resources:
      - networkpolicies/status
    verbs:
      - create
      - get
  - apiGroups:
      - authentication.k8s.io
    resources:
      - tokenreviews
    verbs:
      - create
  - apiGroups:
      - authorization.k8s.io
    resources:
      - subjectaccessreviews
    verbs:
      - create
  # This is the content of built-in role kube-system/extension-apiserver-authentication-reader.
  # But it doesn't have list/watch permission before K8s v1.17.0 so the extension apiserver (kubefay-agent) will
  # have permission issue after bumping up apiserver library to a version that supports dynamic authentication.
  # See https://github.com/kubernetes/kubernetes/pull/85375
  # To support K8s clusters older than v1.17.0, we grant the required permissions directly instead of relying on
  # the extension-apiserver-authentication role.
  - apiGroups:
      - ""
    resourceNames:
      - extension-apiserver-authentication
    resources:
      - configmaps
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - ""
    resources:
      - configmaps
    resourceNames:
      - kubefay-ca
    verbs:
      - get
      - watch
      - list
  - apiGroups:
      - crd.kubefay.io
    resources:
      - traceflows
      - traceflows/status
    verbs:
      - get
      - watch
      - list
      - update
      - patch
      - create
      - delete
  - apiGroups:
      - crd.kubefay.io
    resources:
      - egresses
    verbs:
      - get
      - watch
      - list
  - apiGroups:
      - crd.kubefay.io
    resources:
      - egresses/status
    verbs:
      - update
  - apiGroups:
      - crd.kubefay.io
    resources:
      - externalippools
      - ippools
      - trafficcontrols
    verbs:
      - get
      - watch
      - list
  - apiGroups:
      - crd.kubefay.io
    resources:
      - ippools/status
    verbs:
      - update
  - apiGroups:
      - k8s.cni.cncf.io
    resources:
      - network-attachment-definitions
    verbs:
      - get
      - list
      - watch
---
# Source: kubefay/templates/antctl/clusterrole.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: antctl
  labels:
    app: kubefay
rules:
  - apiGroups:
      - controlplane.kubefay.io
    resources:
      - networkpolicies
      - appliedtogroups
      - addressgroups
    verbs:
      - get
      - list
  - apiGroups:
      - stats.kubefay.io
    resources:
      - networkpolicystats
      - kubefayclusternetworkpolicystats
      - kubefaynetworkpolicystats
    verbs:
      - get
      - list
  - apiGroups:
      - system.kubefay.io
    resources:
      - controllerinfos
      - agentinfos
    verbs:
      - get
  - apiGroups:
      - system.kubefay.io
    resources:
      - supportbundles
    verbs:
      - get
      - post
  - apiGroups:
      - system.kubefay.io
    resources:
      - supportbundles/download
    verbs:
      - get
  - nonResourceURLs:
      - /agentinfo
      - /addressgroups
      - /appliedtogroups
      - /loglevel
      - /networkpolicies
      - /ovsflows
      - /ovstracing
      - /podinterfaces
      - /featuregates
      - /serviceexternalip
    verbs:
      - get
---
# Source: kubefay/templates/cluster-identity-reader/clusterrolebinding.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: kubefay-cluster-identity-reader
  labels:
    app: kubefay
rules:
  - apiGroups:
      - ""
    resources:
      - configmaps
    resourceNames:
      - kubefay-cluster-identity
    verbs:
      - get
---
# Source: kubefay/templates/controller/clusterrole.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: kubefay-controller
  labels:
    app: kubefay
rules:
  - apiGroups:
      - ""
    resources:
      - pods
      - services
      - namespaces
      - configmaps
    verbs:
      - get
      - watch
      - list
  - apiGroups:
      - ""
    resources:
      - nodes
    verbs:
      - get
      - watch
      - list
      - patch
  - apiGroups:
      - ""
    resources:
      - services/status
    verbs:
      - update
  - apiGroups:
      - networking.k8s.io
    resources:
      - networkpolicies
    verbs:
      - get
      - watch
      - list
  - apiGroups:
      - authentication.k8s.io
    resources:
      - tokenreviews
    verbs:
      - create
  - apiGroups:
      - authorization.k8s.io
    resources:
      - subjectaccessreviews
    verbs:
      - create
  - apiGroups:
      - apiextensions.k8s.io
    resources:
      - customresourcedefinitions
    verbs:
      - get
      - update
  # This is the content of built-in role kube-system/extension-apiserver-authentication-reader.
  # But it doesn't have list/watch permission before K8s v1.17.0 so the extension apiserver (kubefay-controller) will
  # have permission issue after bumping up apiserver library to a version that supports dynamic authentication.
  # See https://github.com/kubernetes/kubernetes/pull/85375
  # To support K8s clusters older than v1.17.0, we grant the required permissions directly instead of relying on
  # the extension-apiserver-authentication role.
  - apiGroups:
      - ""
    resourceNames:
      - extension-apiserver-authentication
    resources:
      - configmaps
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - ""
    resources:
      - configmaps
    resourceNames:
      - kubefay-ca
      - kubefay-cluster-identity
    verbs:
      - get
      - update
  - apiGroups:
      - ""
    resources:
      - configmaps
    verbs:
      - create
  - apiGroups:
      - apiregistration.k8s.io
    resources:
      - apiservices
    resourceNames:
      - v1alpha1.stats.kubefay.io
      - v1beta1.system.kubefay.io
      - v1beta2.controlplane.kubefay.io
    verbs:
      - get
      - update
  - apiGroups:
      - apiregistration.k8s.io
    resources:
      - apiservices
    resourceNames:
      - v1beta1.networking.kubefay.tanzu.vmware.com
      - v1beta1.controlplane.kubefay.tanzu.vmware.com
      - v1alpha1.stats.kubefay.tanzu.vmware.com
      - v1beta1.system.kubefay.tanzu.vmware.com
      - v1beta2.controlplane.kubefay.tanzu.vmware.com
    verbs:
      - delete
  - apiGroups:
      - admissionregistration.k8s.io
    resources:
      - mutatingwebhookconfigurations
      - validatingwebhookconfigurations
    resourceNames:
      # always give permissions for labelsmutator.kubefay.io, even when the
      # feature is disabled, to avoid errors in kubefay-controller when updating
      # the CA cert.
      - labelsmutator.kubefay.io
      - crdmutator.kubefay.io
      - crdvalidator.kubefay.io
    verbs:
      - get
      - update
  - apiGroups:
      - crd.kubefay.io
    resources:
      - kubefaycontrollerinfos
    verbs:
      - get
      - create
      - update
      - delete
  - apiGroups:
      - crd.kubefay.io
    resources:
      - kubefayagentinfos
    verbs:
      - list
      - delete
  - apiGroups:
      - crd.kubefay.io
    resources:
      - clusternetworkpolicies
      - networkpolicies
    verbs:
      - get
      - watch
      - list
      - update
      - patch
      - create
      - delete
  - apiGroups:
      - crd.kubefay.io
    resources:
      - clusternetworkpolicies/status
      - networkpolicies/status
    verbs:
      - update
  - apiGroups:
      - crd.kubefay.io
    resources:
      - tiers
    verbs:
      - get
      - watch
      - list
      - update
      - patch
      - create
      - delete
  - apiGroups:
      - crd.kubefay.io
    resources:
      - traceflows
      - traceflows/status
    verbs:
      - get
      - watch
      - list
      - update
      - patch
      - create
      - delete
  - apiGroups:
      - crd.kubefay.io
    resources:
      - externalentities
      - clustergroups
    verbs:
      - get
      - watch
      - list
      - update
      - patch
      - create
      - delete
  - apiGroups:
      - crd.kubefay.io
    resources:
      - clustergroups/status
    verbs:
      - update
  - apiGroups:
      - crd.kubefay.io
    resources:
      - egresses
    verbs:
      - get
      - watch
      - list
      - update
      - patch
  - apiGroups:
      - crd.kubefay.io
    resources:
      - externalippools
      - ippools
    verbs:
      - get
      - watch
      - list
  - apiGroups:
      - crd.kubefay.io
    resources:
      - externalippools/status
      - ippools/status
    verbs:
      - update
  - apiGroups:
      - apps
    resources:
      - statefulsets
    verbs:
      - get
      - list
      - watch
---
# Source: kubefay/templates/crds-rbac/clusterroles.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: aggregate-kubefay-policies-edit
  labels:
    app: kubefay
    # Add these permissions to the "admin" and "edit" default roles.
    rbac.authorization.k8s.io/aggregate-to-admin: "true"
    rbac.authorization.k8s.io/aggregate-to-edit: "true"
rules:
- apiGroups: ["crd.kubefay.io"]
  resources: ["clusternetworkpolicies", "networkpolicies"]
  verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
---
# Source: kubefay/templates/crds-rbac/clusterroles.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: aggregate-kubefay-policies-view
  labels:
    app: kubefay
    # Add these permissions to the "view" default role.
    rbac.authorization.k8s.io/aggregate-to-view: "true"
rules:
- apiGroups: ["crd.kubefay.io"]
  resources: ["clusternetworkpolicies", "networkpolicies"]
  verbs: ["get", "list", "watch"]
---
# Source: kubefay/templates/crds-rbac/clusterroles.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: aggregate-traceflows-edit
  labels:
    app: kubefay
    # Add these permissions to the "admin" and "edit" default roles.
    rbac.authorization.k8s.io/aggregate-to-admin: "true"
    rbac.authorization.k8s.io/aggregate-to-edit: "true"
rules:
- apiGroups: ["crd.kubefay.io"]
  resources: ["traceflows"]
  verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
---
# Source: kubefay/templates/crds-rbac/clusterroles.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: aggregate-traceflows-view
  labels:
    app: kubefay
    # Add these permissions to the "view" default role.
    rbac.authorization.k8s.io/aggregate-to-view: "true"
rules:
- apiGroups: ["crd.kubefay.io"]
  resources: ["traceflows"]
  verbs: ["get", "list", "watch"]
---
# Source: kubefay/templates/crds-rbac/clusterroles.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: aggregate-kubefay-clustergroups-edit
  labels:
    app: kubefay
    # Add these permissions to the "admin" and "edit" default roles.
    rbac.authorization.k8s.io/aggregate-to-admin: "true"
    rbac.authorization.k8s.io/aggregate-to-edit: "true"
rules:
- apiGroups: ["crd.kubefay.io"]
  resources: ["clustergroups"]
  verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
---
# Source: kubefay/templates/crds-rbac/clusterroles.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: aggregate-kubefay-clustergroups-view
  labels:
    app: kubefay
    # Add these permissions to the "view" default role.
    rbac.authorization.k8s.io/aggregate-to-view: "true"
rules:
- apiGroups: ["crd.kubefay.io"]
  resources: ["clustergroups"]
  verbs: ["get", "list", "watch"]
---
# Source: kubefay/templates/agent/clusterrolebinding.yaml
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: kubefay-agent
  labels:
    app: kubefay
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: kubefay-agent
subjects:
  - kind: ServiceAccount
    name: kubefay-agent
    namespace: kube-system
---
# Source: kubefay/templates/antctl/clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    app: kubefay
  name: antctl
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: antctl
subjects:
  - kind: ServiceAccount
    name: antctl
    namespace: kube-system
---
# Source: kubefay/templates/controller/clusterrolebinding.yaml
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: kubefay-controller
  labels:
    app: kubefay
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: kubefay-controller
subjects:
  - kind: ServiceAccount
    name: kubefay-controller
    namespace: kube-system
---
# Source: kubefay/templates/agent/daemonset.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: kubefay-agent
  namespace: kube-system
  labels:
    app: kubefay
    component: kubefay-agent
spec:
  selector:
    matchLabels:
      app: kubefay
      component: kubefay-agent
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      annotations:
        # Starting with v1.21, Kubernetes supports default container annotation.
        # Using "kubectl logs/exec/attach/cp" doesn't have to specify "-c kubefay-agent" when troubleshooting.
        kubectl.kubernetes.io/default-container: kubefay-agent
        # Automatically restart Pods with a RollingUpdate if the ConfigMap changes
        # See https://helm.sh/docs/howto/charts_tips_and_tricks/#automatically-roll-deployments
        checksum/config: 03ee0481c65f3ec8ff9e879ff10c3cf65991a347a7aec1c9bc866b019ec470f1
      labels:
        app: kubefay
        component: kubefay-agent
    spec:
      hostNetwork: true
      dnsPolicy: ClusterFirstWithHostNet
      priorityClassName: system-node-critical
      nodeSelector:
        kubernetes.io/os: linux
      tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        - effect: NoSchedule
          operator: Exists
        - effect: NoExecute
          operator: Exists
      serviceAccountName: kubefay-agent
      initContainers:
        - name: install-cni
          image: "kubefay/base-ubuntu:latest"
          imagePullPolicy: Never
          resources:
            requests:
              cpu: 100m
          command: ["pwd"]
          securityContext:
            capabilities:
              add:
                # SYS_MODULE is required to load the OVS kernel module.
                - SYS_MODULE
          env:
            # SKIP_CNI_BINARIES takes in values as a comma separated list of
            # binaries that need to be skipped for installation, e.g. "portmap, bandwidth".
            - name: SKIP_CNI_BINARIES
              value: ""
          volumeMounts:
          - name: kubefay-config
            mountPath: /etc/kubefay/kubefay-cni.conflist
            subPath: kubefay-cni.conflist
            readOnly: true
          - name: host-cni-conf
            mountPath: /host/etc/cni/net.d
          - name: host-cni-bin
            mountPath: /host/opt/cni/bin
          # For loading the OVS kernel module.
          - name: host-lib-modules
            mountPath: /lib/modules
            readOnly: true
          # For changing the default permissions of the run directory.
          - name: host-var-run-kubefay
            mountPath: /var/run/kubefay
      containers:
        - name: kubefay-agent
          image: "kubefay/base-ubuntu:latest"
          imagePullPolicy: IfNotPresent
          command: ["sleep"]
          # Log to both "/var/log/kubefay/" and stderr (so "kubectl logs" can work).-
          args:
            - "1000000"
            # - "--config=/etc/kubefay/kubefay-agent.conf"
            # - "--logtostderr=false"
            # - "--log_dir=/var/log/kubefay"
            # - "--alsologtostderr"
            # - "--log_file_max_size=100"
            # - "--log_file_max_num=4"
          env:
            # Provide pod and node information for clusterinformation CRD.
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
          resources:
            requests:
              cpu: 200m
          ports:
            - containerPort: 10350
              name: api
              protocol: TCP
          # livenessProbe:
          #   exec:
          #     command:
          #       - /bin/sh
          #       - -c
          #       - container_liveness_probe agent
          #   initialDelaySeconds: 5
          #   timeoutSeconds: 5
          #   periodSeconds: 10
          #   failureThreshold: 5
          # readinessProbe:
          #   httpGet:
          #     host: localhost
          #     path: /readyz
          #     port: api
          #     scheme: HTTPS
            # initialDelaySeconds: 5
            # timeoutSeconds: 5
            # periodSeconds: 10
            # # In large-scale clusters, it may take up to 40~50 seconds for the kubefay-agent to reconnect to the kubefay
            # # Service after the kubefay-controller restarts. The kubefay-agent shouldn't be reported as NotReady in this
            # # scenario, otherwise the DaemonSet controller would restart all agents at once, as opposed to performing a
            # # rolling update. Set failureThreshold to 8 so it can tolerate 70s of disconnection.
            # failureThreshold: 8
          securityContext:
            # kubefay-agent needs to perform sysctl configuration.
            privileged: true
          volumeMounts:
          - name: kubefay-config
            mountPath: /etc/kubefay/kubefay-agent.conf
            subPath: kubefay-agent.conf
            readOnly: true
          - name: host-var-run-kubefay
            mountPath: /var/run/kubefay
          - name: host-var-run-kubefay
            mountPath: /var/run/openvswitch
            subPath: openvswitch
          # host-local IPAM stores allocated IP addresses as files in /var/lib/cni/networks/$NETWORK_NAME.
          # Mount a sub-directory of host-var-run-kubefay to it for persistence of IP allocation.
          - name: host-var-run-kubefay
            mountPath: /var/lib/cni
            subPath: cni
          # We need to mount both the /proc directory and the /var/run/netns directory so that
          # kubefay-agent can open the network namespace path when setting up Pod
          # networking. Different container runtimes may use /proc or /var/run/netns when invoking
          # the CNI commands. Docker uses /proc and containerd uses /var/run/netns.
          - name: host-var-log-kubefay
            mountPath: /var/log/kubefay
          - name: host-proc
            mountPath: /host/proc
            readOnly: true
          - name: host-var-run-netns
            mountPath: /host/var/run/netns
            readOnly: true
            # When a container is created, a mount point for the network namespace is added under
            # /var/run/netns on the host, which needs to be propagated to the kubefay-agent container.
            mountPropagation: HostToContainer
          - name: xtables-lock
            mountPath: /run/xtables.lock
        - name: kubefay-ovs
          image: "kubefay/base-ubuntu:latest"
          imagePullPolicy: IfNotPresent
          resources:
            requests:
              cpu: 200m
          command: ["sleep"]
          args:
            - "100000000"
            # - "--log_file_max_num=4"
          securityContext:
            # capabilities required by OVS daemons
            capabilities:
              add:
                - SYS_NICE
                - NET_ADMIN
                - SYS_ADMIN
                - IPC_LOCK
          # livenessProbe:
          #   exec:
          #     # docker CRI doesn't honor timeoutSeconds, add "timeout" to the command as a workaround.
          #     # https://github.com/kubernetes/kubernetes/issues/51901
          #     command:
          #       - /bin/sh
          #       - -c
          #       - timeout 10 container_liveness_probe ovs
          #   initialDelaySeconds: 5
          #   timeoutSeconds: 10
          #   periodSeconds: 10
          #   failureThreshold: 5
          volumeMounts:
          - name: host-var-run-kubefay
            mountPath: /var/run/openvswitch
            subPath: openvswitch
          - name: host-var-log-kubefay
            mountPath: /var/log/openvswitch
            subPath: openvswitch
      volumes:
        - name: kubefay-config
          configMap:
            name: kubefay-config
        - name: host-cni-conf
          hostPath:
            path: /etc/cni/net.d
        - name: host-cni-bin
          hostPath:
            path: /opt/cni/bin
        - name: host-proc
          hostPath:
            path: /proc
        - name: host-var-run-netns
          hostPath:
            path: /var/run/netns
        - name: host-var-run-kubefay
          hostPath:
            path: /var/run/kubefay
            # we use subPath to create run subdirectories for different component (e.g. OVS) and
            # subPath requires the base volume to exist
            type: DirectoryOrCreate
        - name: host-var-log-kubefay
          hostPath:
            path: /var/log/kubefay
            # we use subPath to create logging subdirectories for different component (e.g. OVS)
            type: DirectoryOrCreate
        - name: host-lib-modules
          hostPath:
            path: /lib/modules
        - name: xtables-lock
          hostPath:
            path: /run/xtables.lock
            type: FileOrCreate